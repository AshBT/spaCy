=================
The Lexeme Object
=================

The Lexeme object represents a lexical *type*, stored in the vocabulary ---
as opposed to a *token*, occurring in a document.

Lexemes store various features, so that these features can be computed once per
type, rather than once per token.  As job sizes grow, this can amount to a substantial
efficiency improvement.

All Lexeme attributes are therefore context independent, as a single lexeme
is reused for all usages of that word. Lexemes are keyed by the "orth"
attribute.

All Lexeme attributes are accessible directly on the Token object.


.. py:class:: Lexeme

  **String Views**

  .. py:attribute:: orth / orth\_

    The form of the word with no string normalization or processing, as it
    appears in the string, without trailing whitespace.

  .. py:attribute:: lower / lower\_
    The form of the word, but forced to lower-case, i.e. lower = word.orth\_.lower()

  .. py:attribute:: norm / norm\_
    The form of the word, after language-specific normalizations have been
    applied.

  .. py:attribute:: shape / shape\_
    A transform of the word's string, to show orthographic features.  The
    characters a-z are mapped to x, A-Z is mapped to X, 0-9 is mapped to d.
    After these mappings, sequences of 4 or more of the same character are
    truncated to length 4.  Examples: C3Po --> XdXx, favorite --> xxxx,
    :) --> :)

  .. py:attribute:: prefix / prefix\_
    A length-N substring from the start of the word.  Length may vary by
    language; currently for English n=1, i.e. prefix = word.orth\_[:1]

  .. py:attribute:: suffix / suffix\_

    A length-N substring from the end of the word.  Length may vary by
    language; currently for English n=3, i.e. suffix = word.orth\_[-3:]

  **Boolean Features**

  .. py:method:: check_flag(self, attr_id_t flag_id)

  .. py:attribute:: is_oov

    Is the word out-of-vocabulary?

  .. py:attribute:: is_alpha

    Equivalent to `word.orth_.isalpha()`

  .. py:attribute:: is_ascii

    Equivalent to `any(ord(c) >= 128 for c in word.orth_)`

  .. py:attribute:: is_digit

    Equivalent to `word.orth_.isdigit()`

  .. py:attribute:: is_lower

    Equivalent to `word.orth_.islower()`

  .. py:attribute:: is_title

    Equivalent to `word.orth_.istitle()`

  .. py:attribute:: is_punct

    Equivalent to `word.orth_.ispunct()`

  .. py:attribute:: is_space

    Equivalent to `word.orth_.isspace()`

  .. py:attribute:: like_url

    Does the word resembles a URL?

  .. py:attribute:: like_num

    Does the word represent a number? e.g. "10.9", "10", "ten", etc

  .. py:attribute:: like_email

    Does the word resemble an email?

  **Distributional Features**

  .. py:attribute:: prob

    The unigram log-probability of the word, estimated from counts from a
    large corpus, smoothed using Simple Good Turing estimation.

  .. py:attribute:: cluster

    The Brown cluster ID of the word.  These are often useful features for
    linear models.  If you're using a non-linear model, particularly
    a neural net or random forest, consider using the real-valued word
    representation vector, in Token.repvec, instead.

  .. py:attribute:: repvec

    A "word embedding" representation: a dense real-valued vector that supports
    similarity queries between words.  By default, spaCy currently loads
    vectors produced by the Levy and Goldberg (2014) dependency-based word2vec
    model.
